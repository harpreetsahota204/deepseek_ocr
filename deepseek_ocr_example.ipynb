{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# DeepSeek-OCR FiftyOne Integration Example\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/harpreetsahota204/deepseek_ocr/blob/main/deepseek_ocr_example.ipynb)\n",
        "\n",
        "This notebook demonstrates how to use DeepSeek-OCR as a FiftyOne zoo model for document analysis and OCR tasks.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Installation\n",
        "\n",
        "Install the required dependencies. Note: DeepSeek-OCR requires specific versions of transformers and tokenizers.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install transformers==4.46.3\n",
        "!pip install tokenizers==0.20.3\n",
        "!pip install addict\n",
        "!pip install fiftyone\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Optional: GPU Acceleration\n",
        "\n",
        "For faster inference on GPU, install Flash Attention:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install flash-attn==2.7.3 --no-build-isolation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load a Dataset\n",
        "\n",
        "Load a sample document dataset from Hugging Face:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import fiftyone as fo\n",
        "from fiftyone.utils.huggingface import load_from_hub\n",
        "\n",
        "# Load the dataset\n",
        "# Note: other available arguments include 'max_samples', etc\n",
        "dataset = load_from_hub(\"Voxel51/document-haystack-10pages\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Register the Zoo Model Source\n",
        "\n",
        "Register the DeepSeek-OCR model as a remote FiftyOne zoo model source:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import fiftyone.zoo as foz\n",
        "\n",
        "# Register the model source\n",
        "foz.register_zoo_model_source(\n",
        "    \"https://github.com/harpreetsahota204/deepseek_ocr\",\n",
        "    overwrite=True  # This will make sure you're always using the latest implementation\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load the Model\n",
        "\n",
        "Load the DeepSeek-OCR model from the zoo:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the model\n",
        "model = foz.load_zoo_model(\"deepseek-ai/DeepSeek-OCR\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Understanding Resolution Modes\n",
        "\n",
        "DeepSeek-OCR provides five resolution modes optimized for different document types:\n",
        "\n",
        "**Single-View Modes** (`crop_mode=False`):\n",
        "- **`\"tiny\"`** - 512x512 resolution, 64 vision tokens. Fastest, for very simple documents.\n",
        "- **`\"small\"`** - 640x640 resolution, 100 vision tokens. Fast, for simple receipts/forms.\n",
        "- **`\"base\"`** - 1024x1024 resolution, 256 vision tokens. Balanced, for standard documents.\n",
        "- **`\"large\"`** - 1280x1280 resolution, 400 vision tokens. Highest quality, slower.\n",
        "\n",
        "**Multi-View Mode**:\n",
        "- **`\"gundam\"`** (default) - 1024 base + 640 patches, variable tokens. Multi-view for complex layouts with tables, multi-column documents, and academic papers.\n",
        "\n",
        "The model automatically handles any input image size. You choose the mode based on document complexity, not your image dimensions.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Example 1: Grounding Mode - Extract Text with Bounding Boxes\n",
        "\n",
        "Use grounding mode to extract text along with bounding box coordinates:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Grounding Mode - Extract text with bounding boxes\n",
        "model.resolution_mode = \"gundam\"\n",
        "model.operation = \"grounding\"\n",
        "\n",
        "dataset.apply_model(model, label_field=\"text_detections\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Example 2: Free OCR - Text Extraction Only\n",
        "\n",
        "Extract text without bounding boxes:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Free OCR\n",
        "model.operation = \"ocr\"\n",
        "dataset.apply_model(model, label_field=\"text_extraction\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Example 3: Describe Mode - Document Description\n",
        "\n",
        "Generate descriptions of document content:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Describe mode\n",
        "model.operation = \"describe\"\n",
        "dataset.apply_model(model, label_field=\"doc_description\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Example 4: Custom Prompt\n",
        "\n",
        "Use a custom prompt to guide the model toward specific extraction tasks:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Custom prompt\n",
        "model.prompt = \"<image>\\n<|grounding|>Locate <|ref|>The secret<|/ref|> in the image.\"\n",
        "dataset.apply_model(model, label_field=\"custom_detections\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualize Results\n",
        "\n",
        "Launch the FiftyOne App to visualize the results:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "session = fo.launch_app(dataset)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Optional: Install Caption Viewer Plugin\n",
        "\n",
        "For better visualization of extracted text and captions:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!fiftyone plugins download https://github.com/mythrandire/caption-viewer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Additional Examples\n",
        "\n",
        "### Using Different Resolution Modes\n",
        "\n",
        "Try different resolution modes for different document types:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fast processing for simple documents\n",
        "model.resolution_mode = \"small\"\n",
        "model.operation = \"ocr\"\n",
        "dataset.apply_model(model, label_field=\"fast_ocr\")\n",
        "\n",
        "# High quality for complex documents\n",
        "model.resolution_mode = \"large\"\n",
        "model.operation = \"grounding\"\n",
        "dataset.apply_model(model, label_field=\"high_quality_detections\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Custom Prompts for Specific Tasks\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract tables with bounding boxes\n",
        "model.prompt = \"<image>\\n<|grounding|>Extract all table content.\"\n",
        "dataset.apply_model(model, label_field=\"table_detections\")\n",
        "\n",
        "# Extract headers and titles\n",
        "model.prompt = \"<image>\\n<|grounding|>Find all headers and section titles.\"\n",
        "dataset.apply_model(model, label_field=\"header_detections\")\n",
        "\n",
        "# Summarize document\n",
        "model.prompt = \"<image>\\nSummarize the main points in bullet format.\"\n",
        "dataset.apply_model(model, label_field=\"summary\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Resources\n",
        "\n",
        "- **GitHub Repository:** https://github.com/harpreetsahota204/deepseek_ocr\n",
        "- **Official DeepSeek-OCR:** https://github.com/deepseek-ai/DeepSeek-OCR\n",
        "- **Model Card:** https://huggingface.co/deepseek-ai/DeepSeek-OCR\n",
        "- **FiftyOne Documentation:** https://docs.voxel51.com/\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
